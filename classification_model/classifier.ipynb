{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec63c62",
   "metadata": {},
   "source": [
    "## Features:\n",
    "### DNA features:\n",
    "- 3-mer frequencies\n",
    "- GC-content\n",
    "- sequence length\n",
    "- start codon (is ATG?)\n",
    "\n",
    "### Protein features:\n",
    "- ESM3 embeddings\n",
    "- protein length\n",
    "- Secondary Structure related\n",
    "    - Secondary Structure Content (e.g. alpha helicex, sheets, coils)\n",
    "    - Solvent Accessibility\n",
    "    - Secondary Structure Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf9a6fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "from huggingface_hub import login\n",
    "from esm.models.esm3 import ESM3\n",
    "from esm.sdk.api import ESMProtein, SamplingConfig, GenerationConfig\n",
    "from esm.utils.constants.models import ESM3_OPEN_SMALL\n",
    "import tqdm\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c9d2a4",
   "metadata": {},
   "source": [
    "## Import datasets and organize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5eb3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_to_df(path):\n",
    "    \"\"\"Parses either a folder of FASTA files, or a single FASTA file into a pandas dataframe.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    # Determine if path is a file or folder\n",
    "    if os.path.isfile(path):\n",
    "        files = [path]\n",
    "    elif os.path.isdir(path):\n",
    "        files = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "\n",
    "    for file in files:\n",
    "        for record in SeqIO.parse(file, \"fasta\"):\n",
    "            desc = record.description\n",
    "            ## This is either [gene=_] or [locus_tag=_]\n",
    "            prot_id = next(  ## For fasta with [protein_id] fields\n",
    "                (x.split(\"=\")[1][:-1] for x in desc.split() if x.startswith(\"[gene=\")),\n",
    "                next(\n",
    "                    (\n",
    "                        \"gene-\" + x.split(\"=\")[1][:-1]\n",
    "                        for x in desc.split()\n",
    "                        if x.startswith(\"[locus_tag=\")\n",
    "                    ),\n",
    "                    None,\n",
    "                ),\n",
    "            )\n",
    "            if prot_id:\n",
    "                data.append((prot_id, str(record.seq)))\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"id\", \"sequence\"])\n",
    "\n",
    "\n",
    "def load_dataset(\n",
    "    dataset_name, phage_accession, gene_classification, aa_fasta, na_fasta\n",
    "):\n",
    "    \"\"\"\n",
    "    For a dataset with input files above:\n",
    "    Return a dataset with columns: gene, classification, aa_seq, na_seq and dataset_name, phage_accession\n",
    "    \"\"\"\n",
    "    # Create dataframe for each file\n",
    "    df_class = pd.read_csv(gene_classification)\n",
    "\n",
    "    df_proteins = fasta_to_df(aa_fasta)\n",
    "    df_proteins.rename(columns={\"id\": \"gene\", \"sequence\": \"aa_seq\"}, inplace=True)\n",
    "\n",
    "    df_genes = fasta_to_df(na_fasta)\n",
    "    df_genes.rename(columns={\"id\": \"gene\", \"sequence\": \"na_seq\"}, inplace=True)\n",
    "\n",
    "    # Combine dataframes into one on \"gene\"-column\n",
    "    df_combined = df_class.merge(df_proteins, on=\"gene\", how=\"outer\").merge(\n",
    "        df_genes, on=\"gene\", how=\"outer\"\n",
    "    )\n",
    "\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e453c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 49 rows.\n",
      "(1167, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load and combine all datasets listed in accession_list.csv\n",
    "master_list = pd.read_csv(\"data/datasets/accession_list.csv\")\n",
    "\n",
    "all_datasets = []\n",
    "\n",
    "for _, row in master_list.iterrows():\n",
    "    dataset_name = row[\"dataset\"]\n",
    "    phage_accession = row[\"NCBI GenBank accession\"]\n",
    "\n",
    "    gene_classification = f\"data/datasets/{dataset_name}/gene_classification.csv\"\n",
    "    aa_fasta = f\"data/proteins_aa/{phage_accession}.fasta\"\n",
    "    na_fasta = f\"data/proteins_na/{phage_accession}.fasta\"\n",
    "\n",
    "    df = load_dataset(\n",
    "        dataset_name, phage_accession, gene_classification, aa_fasta, na_fasta\n",
    "    )\n",
    "    all_datasets.append(df)\n",
    "\n",
    "# Combine into one dataframe\n",
    "df_all = pd.concat(all_datasets, ignore_index=True)\n",
    "# Drop rows with na values\n",
    "df_clean = df_all.dropna()\n",
    "\n",
    "print(f\"Dropped {len(df_all) - len(df_clean)} rows.\")\n",
    "\n",
    "# df_clean.to_csv(\"out.csv\")\n",
    "print(df_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d7fda",
   "metadata": {},
   "source": [
    "## Get DNA features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee4438",
   "metadata": {},
   "source": [
    "### K-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "020bfc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of k-mer features: 70\n",
      "First 5 k-mers: ['aaa' 'aac' 'aag' 'aat' 'aca']\n"
     ]
    }
   ],
   "source": [
    "df = df_clean.copy()\n",
    "\n",
    "\n",
    "def get_kmers(sequence, size=3):\n",
    "    return [sequence[x : x + size] for x in range(len(sequence) - size + 1)]\n",
    "\n",
    "\n",
    "df[\"kmers\"] = df[\"na_seq\"].apply(lambda x: \" \".join(get_kmers(x, size=3)))\n",
    "\n",
    "# Convert to numerical feature\n",
    "vectorizer = CountVectorizer()\n",
    "# This normalizes for sequence length (TODO: test this)\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_kmers = vectorizer.fit_transform(df[\"kmers\"])\n",
    "\n",
    "\n",
    "kmer_features = vectorizer.get_feature_names_out()\n",
    "print(f\"Number of k-mer features: {len(kmer_features)}\")\n",
    "print(f\"First 5 k-mers: {kmer_features[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331bb0c7",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b365774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           gene classification  \\\n",
      "0     gene-PPLUZ19_PPLUZ19_gp20         middle   \n",
      "1                         gp0.1         middle   \n",
      "2                           gp1          early   \n",
      "3                          gp10         middle   \n",
      "4                          gp11         middle   \n",
      "...                         ...            ...   \n",
      "1211             gene-M172_gp50           late   \n",
      "1212             gene-M172_gp51           late   \n",
      "1213             gene-M172_gp52           late   \n",
      "1214             gene-M172_gp53           late   \n",
      "1215             gene-M172_gp54           late   \n",
      "\n",
      "                                                 aa_seq  \\\n",
      "0     MSKRDVVLDIEKGIWRGVDQNDKAVEAIIKKHGYVIVEPKIDGCRA...   \n",
      "1            MSADDPEEYAQDKPEPLILQGLCQCQGLSLEALPPRGFKRQT   \n",
      "2     MAHFKAKAPKSPFAAQVAYWRDWEAKRTKLIAQDNVEGRKELRKMR...   \n",
      "3     MTNVNTTTETTAAAVLGAKLIKKPASVEDFRNNVAFHHNALVKLTE...   \n",
      "4     MSKRNPEHINGTVRSVSVQKLAATQELEDRLEAALAVCQQRAEDID...   \n",
      "...                                                 ...   \n",
      "1211  MILTKDGFSIIRNELFGGKLDQTQVDAINFIVEKATESGLSYPEAA...   \n",
      "1212  MAGKKTGASVSRLCLLHELLVDMFIKDIQDAIEGDYPLASADKNVI...   \n",
      "1213  MIDATFRERFKRLRAHVAQHNDRPELIPKEDREMFALMFAGLFLSF...   \n",
      "1214       MTEQEIKERLTRNWLVINAAKQLVLFVKEKLNEGKSISTKEDQA   \n",
      "1215  MKVNLSALKKIKHSDAVNVVSTLGTIVESAKAVNSVQEYKGKDKVN...   \n",
      "\n",
      "                                                 na_seq  \\\n",
      "0     ATGAGCAAGCGCGACGTGGTACTGGATATCGAGAAAGGCATCTGGC...   \n",
      "1     ATGAGTGCTGACGATCCCGAAGAGTATGCGCAGGACAAGCCAGAAC...   \n",
      "2     ATGGCACACTTCAAGGCTAAGGCTCCCAAGTCGCCCTTTGCTGCTC...   \n",
      "3     ATGACCAACGTCAACACCACCACCGAGACCACCGCCGCTGCTGTCC...   \n",
      "4     ATGAGCAAGCGCAACCCCGAACACATCAACGGCACCGTTCGTAGCG...   \n",
      "...                                                 ...   \n",
      "1211  ATGATTCTGACTAAAGACGGGTTTAGTATTATCCGTAATGAACTAT...   \n",
      "1212  ATGGCAGGTAAGAAAACAGGGGCTAGTGTTAGCCGTCTATGCTTAT...   \n",
      "1213  ATGATTGATGCGACGTTCCGAGAACGCTTTAAAAGATTACGGGCAC...   \n",
      "1214  ATGACAGAACAAGAAATTAAAGAAAGACTAACTCGTAATTGGTTAG...   \n",
      "1215  ATGAAGGTAAATCTATCAGCACTAAAGAAGATCAAGCATAGTGATG...   \n",
      "\n",
      "                                                  kmers  GC_content  \\\n",
      "0     ATG TGA GAG AGC GCA CAA AAG AGC GCG CGC GCG CG...    0.640295   \n",
      "1     ATG TGA GAG AGT GTG TGC GCT CTG TGA GAC ACG CG...    0.542636   \n",
      "2     ATG TGG GGC GCA CAC ACA CAC ACT CTT TTC TCA CA...    0.575439   \n",
      "3     ATG TGA GAC ACC CCA CAA AAC ACG CGT GTC TCA CA...    0.654676   \n",
      "4     ATG TGA GAG AGC GCA CAA AAG AGC GCG CGC GCA CA...    0.644444   \n",
      "...                                                 ...         ...   \n",
      "1211  ATG TGA GAT ATT TTC TCT CTG TGA GAC ACT CTA TA...    0.388889   \n",
      "1212  ATG TGG GGC GCA CAG AGG GGT GTA TAA AAG AGA GA...    0.394822   \n",
      "1213  ATG TGA GAT ATT TTG TGA GAT ATG TGC GCG CGA GA...    0.416409   \n",
      "1214  ATG TGA GAC ACA CAG AGA GAA AAC ACA CAA AAG AG...    0.325926   \n",
      "1215  ATG TGA GAA AAG AGG GGT GTA TAA AAA AAT ATC TC...    0.382353   \n",
      "\n",
      "      gene_length  start_atg  \n",
      "0             948          1  \n",
      "1             129          1  \n",
      "2             285          1  \n",
      "3             417          1  \n",
      "4             360          1  \n",
      "...           ...        ...  \n",
      "1211          558          1  \n",
      "1212          309          1  \n",
      "1213         1938          1  \n",
      "1214          135          1  \n",
      "1215          204          1  \n",
      "\n",
      "[1167 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# GC-content\n",
    "df[\"GC_content\"] = df[\"na_seq\"].apply(lambda x: (x.count(\"G\") + x.count(\"C\")) / len(x))\n",
    "\n",
    "# Sequence length\n",
    "df[\"gene_length\"] = df[\"na_seq\"].apply(len)\n",
    "\n",
    "# ATG start?\n",
    "df[\"start_atg\"] = df[\"na_seq\"].apply(lambda x: int(x.startswith(\"ATG\")))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad2e32",
   "metadata": {},
   "source": [
    "# Get Protein features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f0a5d1",
   "metadata": {},
   "source": [
    "## Structure Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2a1ae1",
   "metadata": {},
   "source": [
    "### Predict Protein Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a58b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESM3 login and download\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d7e2305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc37e4a499f8487b81cefb22bb0fd86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 22 files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# client = ESM3.from_pretrained(ESM3_OPEN_SMALL).to(\"cuda\")\n",
    "client = ESM3.from_pretrained(\"esm3-open\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Don't run this on local hardware\n",
    "\n",
    "# Batch folding (from ESM3 github snippet)\n",
    "outdir = Path(\"./data/protein_structures\")\n",
    "outdir.mkdir(exist_ok=True)\n",
    "\n",
    "proteins = [ESMProtein(sequence=seq) for seq in df[\"aa_seq\"]]\n",
    "configs = [\n",
    "    GenerationConfig(\n",
    "        track=\"structure\", schedule=\"cosine\", num_steps=int(len(prot) / 16)\n",
    "    )\n",
    "    for prot in proteins\n",
    "]\n",
    "# Generate for the structure track.\n",
    "proteins = client.batch_generate(proteins, configs)\n",
    "# Now write sequence and structure to PDB files.\n",
    "for i, p in enumerate(proteins):\n",
    "    assert isinstance(p, ESMProtein), f\"ESMProtein was expected but got {p}\"\n",
    "    p.to_pdb(\n",
    "        f\"./{outdir}/{df.loc[i]['gene']}.pdb\"\n",
    "    )  # This way of naming might be bad (using just number index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aee3e71",
   "metadata": {},
   "source": [
    "Generate dssp files via mkdssp or other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38869307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      gene classification                                             aa_seq  \\\n",
      "0        1           late  MKLIFLSGVKRSGKDTTADFIMSNYSAVKYQLAGPIKDALAYAWGV...   \n",
      "1       10           late  MKQNINIGNVVDDGTGDYLRKGGIKINENFDELYYELGDGDVPYSA...   \n",
      "2       11           late  MSLLNNKAGVISRLADFLGFRPKTGDIDVMNRQSVGSVTISQLAKG...   \n",
      "3       12           late  MSNNTYQHVSNESRYVKFDPTDTNFPPEITDVHAAIAAISPAGVNG...   \n",
      "4       13           late  MSGYNPQNPKELKDVILRRLGAPIINVELTPDQIYDCIQRALELYG...   \n",
      "...    ...            ...                                                ...   \n",
      "1162  vs.5           late  MAKIIIEGSEDVLNAFASGLVTQANSNLMKRGIWVILMEFILRQKF...   \n",
      "1163  vs.6         middle  MKAYQILEGTHKGTIYFEDGIQARIIVSKTFKEDSFVDPEIFYGLH...   \n",
      "1164  vs.7           late  MMTDTQLFEYLYFSPKTIKNKLVNHFEILAKNNILSEFYPKQYKLQ...   \n",
      "1165  vs.8           late  MRDSRQPVIRSSPSAVMGKYRNGQFMCHGMAQTYRAYREEMRTFLT...   \n",
      "1166   wac           late  MTDIVLNDLPFVDGPPAEGQSRISWIKNGEEILGADTQYGSEGSMN...   \n",
      "\n",
      "                                                 na_seq  \\\n",
      "0     ATGAAACTAATCTTTTTAAGCGGTGTAAAGCGTAGTGGAAAAGATA...   \n",
      "1     ATGAAACAAAATATTAATATCGGTAATGTTGTAGATGATGGTACCG...   \n",
      "2     ATGAGTTTACTTAATAATAAAGCGGGAGTTATTTCCCGCTTAGCCG...   \n",
      "3     ATGAGTAATAATACATATCAACACGTTTCTAATGAATCTCGTTATG...   \n",
      "4     ATGTCAGGATATAATCCTCAGAATCCAAAGGAACTCAAAGATGTCA...   \n",
      "...                                                 ...   \n",
      "1162  ATGGCAAAGATAATTATTGAAGGTTCTGAAGATGTGCTAAATGCTT...   \n",
      "1163  ATGAAAGCATATCAAATTCTTGAAGGCACACATAAAGGTACTATTT...   \n",
      "1164  ATGATGACAGACACTCAGCTTTTCGAATATCTTTATTTTTCGCCAA...   \n",
      "1165  ATGAGGGATTCCCGCCAACCTGTAATAAGGTCGAGCCCAAGCGCGG...   \n",
      "1166  ATGACAGATATTGTACTGAATGACTTACCATTCGTTGACGGCCCTC...   \n",
      "\n",
      "                                                  kmers  GC_content  \\\n",
      "0     ATG TGA GAA AAA AAC ACT CTA TAA AAT ATC TCT CT...    0.347107   \n",
      "1     ATG TGA GAA AAA AAC ACA CAA AAA AAA AAT ATA TA...    0.362078   \n",
      "2     ATG TGA GAG AGT GTT TTT TTA TAC ACT CTT TTA TA...    0.356061   \n",
      "3     ATG TGA GAG AGT GTA TAA AAT ATA TAA AAT ATA TA...    0.397096   \n",
      "4     ATG TGT GTC TCA CAG AGG GGA GAT ATA TAT ATA TA...    0.384946   \n",
      "...                                                 ...         ...   \n",
      "1162  ATG TGG GGC GCA CAA AAA AAG AGA GAT ATA TAA AA...    0.378531   \n",
      "1163  ATG TGA GAA AAA AAG AGC GCA CAT ATA TAT ATC TC...    0.404959   \n",
      "1164  ATG TGA GAT ATG TGA GAC ACA CAG AGA GAC ACA CA...    0.290909   \n",
      "1165  ATG TGA GAG AGG GGG GGA GAT ATT TTC TCC CCC CC...    0.368182   \n",
      "1166  ATG TGA GAC ACA CAG AGA GAT ATA TAT ATT TTG TG...    0.372268   \n",
      "\n",
      "      gene_length  start_atg  protein_length  H_frac  E_frac  ._frac  C_frac  \\\n",
      "0             726          1             241     NaN     NaN     NaN     NaN   \n",
      "1            1809          1             602     NaN     NaN     NaN     NaN   \n",
      "2             660          1             219     NaN     NaN     NaN     NaN   \n",
      "3            1584          1             527     NaN     NaN     NaN     NaN   \n",
      "4             930          1             309     NaN     NaN     NaN     NaN   \n",
      "...           ...        ...             ...     ...     ...     ...     ...   \n",
      "1162          177          1              58     NaN     NaN     NaN     NaN   \n",
      "1163          363          1             120     NaN     NaN     NaN     NaN   \n",
      "1164          330          1             109     NaN     NaN     NaN     NaN   \n",
      "1165          660          1             219     NaN     NaN     NaN     NaN   \n",
      "1166         1464          1             487     NaN     NaN     NaN     NaN   \n",
      "\n",
      "      rsa_mean  frac_exposed  transitions_per_residue  \n",
      "0          NaN           NaN                      NaN  \n",
      "1          NaN           NaN                      NaN  \n",
      "2          NaN           NaN                      NaN  \n",
      "3          NaN           NaN                      NaN  \n",
      "4          NaN           NaN                      NaN  \n",
      "...        ...           ...                      ...  \n",
      "1162       NaN           NaN                      NaN  \n",
      "1163       NaN           NaN                      NaN  \n",
      "1164       NaN           NaN                      NaN  \n",
      "1165       NaN           NaN                      NaN  \n",
      "1166       NaN           NaN                      NaN  \n",
      "\n",
      "[1167 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# mmcif files generated outside of this notebook\n",
    "from DSSPparser import parseDSSP\n",
    "\n",
    "# Max ASA values per residue for RSA (relative solvent accessibility) (Tien et al., 2013 (emp.))\n",
    "MAX_ASA = {\n",
    "    \"A\": 121.0,\n",
    "    \"R\": 265.0,\n",
    "    \"N\": 187.0,\n",
    "    \"D\": 187.0,\n",
    "    \"C\": 148.0,\n",
    "    \"Q\": 214.0,\n",
    "    \"E\": 214.0,\n",
    "    \"G\": 97.0,\n",
    "    \"H\": 216.0,\n",
    "    \"I\": 195.0,\n",
    "    \"L\": 191.0,\n",
    "    \"K\": 230.0,\n",
    "    \"M\": 203.0,\n",
    "    \"F\": 228.0,\n",
    "    \"P\": 154.0,\n",
    "    \"S\": 143.0,\n",
    "    \"T\": 163.0,\n",
    "    \"W\": 264.0,\n",
    "    \"Y\": 255.0,\n",
    "    \"V\": 165.0,\n",
    "}\n",
    "\n",
    "# Protein length\n",
    "df[\"protein_length\"] = df[\"aa_seq\"].apply(len)\n",
    "\n",
    "\n",
    "def dssp_features(dssp_file):\n",
    "    features = {}\n",
    "\n",
    "    # Parse dssp file\n",
    "    parser = parseDSSP(dssp_file)\n",
    "    parser.parse()\n",
    "    df_dssp = parser.dictTodataframe()\n",
    "    df_dssp[\"struct\"] = df_dssp[\"struct\"].apply(\n",
    "        lambda x: \".\" if x == \"   \" else x.strip()\n",
    "    )  # replace \" \" with \".\" and strip whitespaces in struc column\n",
    "    # print(df_dssp)\n",
    "\n",
    "    ## Secondary structure content\n",
    "    # dssp: H = helix, E = beta strand, C or . = coil/loop\n",
    "    # The rest (G, I, T, S) are ignored for now\n",
    "    structure_counts = df_dssp[\"struct\"].value_counts()\n",
    "    total = len(df_dssp)\n",
    "    struc_content = {k: v / total for k, v in structure_counts.items()}\n",
    "    # Set default values\n",
    "    for frac in [\"H\", \"E\", \".\", \"C\"]:\n",
    "        struc_content.setdefault(frac, 0.0)\n",
    "    # print(struc_content)\n",
    "\n",
    "    features = {f\"{k}_frac\": struc_content[k] for k in [\"H\", \"E\", \".\", \"C\"]}\n",
    "\n",
    "    ## Solvent Accessibility\n",
    "    # Calculate RSA\n",
    "    df_dssp[\"acc\"] = pd.to_numeric(df_dssp[\"acc\"])\n",
    "    df_dssp[\"rsa\"] = df_dssp.apply(\n",
    "        lambda row: row[\"acc\"] / MAX_ASA.get(row[\"aa\"], np.nan), axis=1\n",
    "    )\n",
    "    # Get mean RSA\n",
    "    features[\"rsa_mean\"] = df_dssp[\"rsa\"].mean().item()\n",
    "\n",
    "    # Fraction of exposed residues (threshold: RSA > 20%  (Chen, Zhou, Nucleic Acids Res, 2005))\n",
    "    features[\"frac_exposed\"] = df_dssp[\"rsa\"].apply(lambda x: x > 0.2).mean().item()\n",
    "\n",
    "    ## Secondary structure transitions per residue\n",
    "    # TODO: Verify viability of this: Count all transistions? combine all helix types etc and then count?\n",
    "    from collections import Counter\n",
    "\n",
    "    transitions = Counter()\n",
    "    structs = df_dssp[\"struct\"].tolist()\n",
    "    for i in range(1, len(structs)):\n",
    "        if not structs[i - 1] == structs[i]:\n",
    "            pair = (structs[i - 1], structs[i])\n",
    "            transitions[pair] += 1\n",
    "    features[\"transitions_per_residue\"] = sum(transitions.values()) / len(structs)\n",
    "    return features\n",
    "\n",
    "\n",
    "dssp_files = Path(\"data/protein_dssp/\").glob(\"*.dssp\")\n",
    "df_features = pd.DataFrame()\n",
    "for file in dssp_files:\n",
    "    df_temp = pd.DataFrame([dssp_features(file)])\n",
    "    df_temp[\"gene\"] = file.name[:-5]\n",
    "    df_features = pd.concat([df_features, df_temp], ignore_index=True)\n",
    "\n",
    "df = df.merge(df_features, on=\"gene\", how=\"outer\")\n",
    "# df = df.dropna()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e2bef3",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c88464",
   "metadata": {},
   "source": [
    "### Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69d7a4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing protein sequences:   2%|‚ñè         | 23/1167 [16:48<13:56:18, 43.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     28\u001b[39m     np.save(\u001b[33m\"\u001b[39m\u001b[33membedding_ids.npy\u001b[39m\u001b[33m\"\u001b[39m, np.array(ids))\n\u001b[32m     29\u001b[39m     np.save(\u001b[33m\"\u001b[39m\u001b[33membeddings.npy\u001b[39m\u001b[33m\"\u001b[39m, np.array(embeddings))\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mprocess_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mprocess_sequences\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     21\u001b[39m protein_id = row[\u001b[33m\"\u001b[39m\u001b[33mgene\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     23\u001b[39m seq = seq[:\u001b[32m1500\u001b[39m]  \u001b[38;5;66;03m# Limit protein length\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m embedding = \u001b[43mget_esm_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m ids.append(protein_id)\n\u001b[32m     26\u001b[39m embeddings.append(embedding)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mget_esm_embedding\u001b[39m\u001b[34m(sequence)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_esm_embedding\u001b[39m(sequence):\n\u001b[32m      2\u001b[39m     protein = ESMProtein(sequence=sequence)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     protein_tensor = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotein\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     result = client.forward_and_sample(\n\u001b[32m      6\u001b[39m         protein_tensor,\n\u001b[32m      7\u001b[39m         SamplingConfig(return_per_residue_embeddings=\u001b[38;5;28;01mTrue\u001b[39;00m, return_mean_embedding=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m      8\u001b[39m     )\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pha/lib/python3.13/site-packages/esm/models/esm3.py:500\u001b[39m, in \u001b[36mESM3.encode\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    481\u001b[39m         reference_sequence = \u001b[38;5;28minput\u001b[39m.sequence\n\u001b[32m    482\u001b[39m     (function_tokens, residue_annotation_tokens) = (\n\u001b[32m    483\u001b[39m         encoding.tokenize_function_annotations(\n\u001b[32m    484\u001b[39m             \u001b[38;5;28minput\u001b[39m.function_annotations,\n\u001b[32m   (...)\u001b[39m\u001b[32m    489\u001b[39m         )\n\u001b[32m    490\u001b[39m     )\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mESMProteinTensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequence\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequence_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstructure_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m    \u001b[49m\u001b[43msecondary_structure\u001b[49m\u001b[43m=\u001b[49m\u001b[43msecondary_structure_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m    \u001b[49m\u001b[43msasa\u001b[49m\u001b[43m=\u001b[49m\u001b[43msasa_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresidue_annotations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresidue_annotation_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoordinates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m500\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pha/lib/python3.13/site-packages/esm/sdk/api.py:221\u001b[39m, in \u001b[36mESMProteinTensor.to\u001b[39m\u001b[34m(self, device_or_dtype)\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, v.to(device_or_dtype))\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m attr.fields(ESMProteinTensor):\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[43m_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pha/lib/python3.13/site-packages/esm/sdk/api.py:218\u001b[39m, in \u001b[36mESMProteinTensor.to.<locals>._to\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    216\u001b[39m v = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, torch.Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_or_dtype\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def get_esm_embedding(sequence):\n",
    "    protein = ESMProtein(sequence=sequence)\n",
    "    protein_tensor = client.encode(protein)\n",
    "\n",
    "    result = client.forward_and_sample(\n",
    "        protein_tensor,\n",
    "        SamplingConfig(return_per_residue_embeddings=True, return_mean_embedding=True),\n",
    "    )\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_sequences(df):\n",
    "    ids = []\n",
    "    embeddings = []\n",
    "\n",
    "    for index, row in tqdm.tqdm(\n",
    "        df.iterrows(), total=len(df), desc=\"Processing protein sequences\"\n",
    "    ):\n",
    "        seq = row[\"aa_seq\"]\n",
    "        protein_id = row[\"gene\"]\n",
    "\n",
    "        seq = seq[:1500]  # Limit protein length\n",
    "        embedding = get_esm_embedding(seq)\n",
    "        ids.append(protein_id)\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    np.save(\"embedding_ids.npy\", np.array(ids))\n",
    "    np.save(\"embeddings.npy\", np.array(embeddings))\n",
    "\n",
    "\n",
    "process_sequences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings from file\n",
    "esm_embeddings = np.load(\n",
    "    \"../esm_embedding_embeddings_fsHits.npy\", allow_pickle=True\n",
    ")  # embedding file\n",
    "esm_embeddings_ids = np.load(\n",
    "    \"../esm_embedding_protein_ids_class.npy\", allow_pickle=True\n",
    ")  # ID file\n",
    "mean_embeddings = [ebd.mean_embedding.cpu() for ebd in esm_embeddings]\n",
    "\n",
    "X_ebd = np.stack(mean_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab879848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# There are as many embeddings as proteins in the dataframe\n",
    "print(len(df))\n",
    "print(len(mean_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e6e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into final feature matrix TODO: Add proteins features\n",
    "X_other = df[[\"GC_content\", \"gene_length\", \"start_atg\"]].values\n",
    "X = hstack([X_kmers, X_other])\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6cd42",
   "metadata": {},
   "source": [
    "# Encoding and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8850d93a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [1 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m y = le.fit_transform(df[\u001b[33m\"\u001b[39m\u001b[33mclassification\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# print(\"Encoded: \", le.fit_transform([0, 1, 2]))\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDecoded: \u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mle\u001b[49m\u001b[43m.\u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Train/test split\u001b[39;00m\n\u001b[32m      9\u001b[39m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[32m     10\u001b[39m     X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pha/lib/python3.13/site-packages/sklearn/preprocessing/_label.py:162\u001b[39m, in \u001b[36mLabelEncoder.inverse_transform\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    156\u001b[39m diff = _setdiff1d(\n\u001b[32m    157\u001b[39m     ar1=y,\n\u001b[32m    158\u001b[39m     ar2=xp.arange(\u001b[38;5;28mself\u001b[39m.classes_.shape[\u001b[32m0\u001b[39m], device=device(y)),\n\u001b[32m    159\u001b[39m     xp=xp,\n\u001b[32m    160\u001b[39m )\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m diff.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % \u001b[38;5;28mstr\u001b[39m(diff))\n\u001b[32m    163\u001b[39m y = xp.asarray(y)\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.take(\u001b[38;5;28mself\u001b[39m.classes_, y, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: y contains previously unseen labels: [1 2]"
     ]
    }
   ],
   "source": [
    "# Encode classifications\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df[\"classification\"])\n",
    "\n",
    "# print(\"Encoded: \", le.fit_transform([0, 1, 2]))\n",
    "print(\"Decoded: \", le.inverse_transform([0, 1, 2]))\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(gamma=2, C=1, random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    MLPClassifier(alpha=1, max_iter=1000, random_state=42),\n",
    "]\n",
    "\n",
    "# Fit each model\n",
    "trained = [model.fit(X_train, y_train) for model in classifiers]\n",
    "\n",
    "\n",
    "# clf = RandomForestClassifier(random_state=91)\n",
    "# clf = KNeighborsClassifier(3)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919995fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, name in zip(trained, names):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"\\n\" + name)\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Evaluate\n",
    "# y_pred = clf.predict(X_test)\n",
    "# print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a34017",
   "metadata": {},
   "source": [
    "| Metric        | Meaning                                                                                                                                                |\n",
    "| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **precision** | Out of all predicted instances of a class, how many were actually correct?<br>**Formula**: TP / (TP + FP)                                              |\n",
    "| **recall**    | Out of all actual instances of a class, how many did the model correctly detect?<br>**Formula**: TP / (TP + FN)                                        |\n",
    "| **f1-score**  | Harmonic mean of precision and recall.<br>Good single metric for imbalanced classes.<br>**Formula**: 2 \\* (precision \\* recall) / (precision + recall) |\n",
    "| **support**   | Number of true examples of each class in the dataset.   \n",
    "|  |  |\n",
    "| **accuracy**     | Overall: (correct predictions) / (total samples)                                                                                 |\n",
    "| **macro avg**    | Unweighted average across all classes.<br>Each class contributes equally (good for comparing classes).                           |\n",
    "| **weighted avg** | Weighted average, where each class's contribution is proportional to its support.<br>More realistic when classes are imbalanced. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cadd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "for clf, name in zip(trained, names):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"\\n\" + name)\n",
    "    ConfusionMatrixDisplay.from_estimator(clf, X_test, y_test)\n",
    "\n",
    "## 0 = early\n",
    "## 1 = late\n",
    "## 2 = middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71738deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import learning_curve\n",
    "# from sklearn.model_selection import ShuffleSplit\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# train_sizes, train_scores, test_scores = learning_curve(\n",
    "#     clf, X, y, cv=5, scoring=\"accuracy\"\n",
    "# )\n",
    "\n",
    "# plt.plot(train_sizes, np.mean(train_scores, axis=1), label=\"Train\")\n",
    "# plt.plot(train_sizes, np.mean(test_scores, axis=1), label=\"Test\")\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"Training Set Size\")\n",
    "# plt.title(\"Learning Curve\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
